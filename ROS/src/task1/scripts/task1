#!/usr/bin/python3

import rospy
import cv2
import numpy as np
import tf2_ros
import os
import shutil
import math
import time
from os.path import dirname, join
from typing import List, Tuple
from tf2_geometry_msgs import PoseStamped

import torch
from torchvision import transforms
from PIL import Image as _i
from facenet_pytorch import InceptionResnetV1


from tf.transformations import *
from cv_bridge import CvBridge, CvBridgeError

from sensor_msgs.msg import Image
from geometry_msgs.msg import PointStamped, Vector3, Pose, Quaternion
from visualization_msgs.msg import Marker, MarkerArray
from std_msgs.msg import  ColorRGBA
from geometry_msgs.msg import PoseWithCovarianceStamped
from actionlib_msgs.msg import GoalID, GoalStatusArray

from sound_play.libsoundplay import SoundClient

from task1_utils import read_path_log_orientation

DEVICE = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
NN_FACE_SIMILARITY_TOLERANCE = 0.75
NUMBER_OF_FACES_ON_THE_MAP = 3

STATUS_DICT = {
    0:"The goal has yet to be processed by the action server",
    1:"The goal is currently being processed by the action server",
    2:"The goal received a cancel request after it started executing and has since completed its execution (Terminal State)",
    3:"The goal was achieved successfully by the action server (Terminal State)",
    4:"The goal was aborted during execution by the action server due to some failure (Terminal State)",
    5:"The goal was rejected by the action server without being processed, because the goal was unattainable or invalid (Terminal State)",
    6:"The goal received a cancel request after it started executing and has not yet completed execution",
    7:"The goal received a cancel request before it started executing but the action server has not yet confirmed that the goal is canceled",
    8:"The goal received a cancel request before it started executing and was successfully cancelled (Terminal State)",
    9:"An action client can determine that a goal is LOST. This should not be sent over the wire by an action server",
}

def speak_to_person():
    """
    Function for speaking to a person.
    """
    soundhandle = SoundClient()
    rospy.sleep(1)

    voice = "voice_kal_diphone"
    volume = 1.0
    text = "Hello, I am your robot friend"
    rospy.loginfo(f"volume: {volume}, voice: {voice}, text:{text}")
    soundhandle.say(text, voice, volume)
    rospy.sleep(1)

class face_localizer:

    def __init__(self):
        rospy.init_node('face_localizer', anonymous=True)

        # An object we use for converting images between ROS format and OpenCV format
        self.bridge = CvBridge()
        
        # The function for performin HOG face detection
        protoPath = join(dirname(__file__), "deploy.prototxt.txt")
        modelPath = join(dirname(__file__), "res10_300x300_ssd_iter_140000.caffemodel")

        self.face_net = cv2.dnn.readNetFromCaffe(protoPath, modelPath)

        # A help variable for holding the dimensions of the image
        self.dims = (0, 0, 0)

        # Marker array object used for showing markers in Rviz
        self.marker_array = MarkerArray()
        self.marker_num = 1

        # Publiser for the visualization markers
        self.markers_pub = rospy.Publisher('face_markers', MarkerArray, queue_size=1000)

        # Object we use for transforming between coordinate frames
        self.tf_buf = tf2_ros.Buffer()
        self.tf_listener = tf2_ros.TransformListener(self.tf_buf)
        
        self.simple_goal_pub = rospy.Publisher("/move_base_simple/goal", PoseStamped, queue_size=10)
        self.cancel_goal_pub = rospy.Publisher("/move_base/cancel", GoalID, queue_size=10)

        self.model = InceptionResnetV1(pretrained='vggface2')
        self.model.to(DEVICE)
        self.model.eval()
        for param in self.model.parameters():
            param.requires_grad = False
        self.transform = transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])

        # full path of the robot
        points_path = os.path.join(os.path.dirname(__file__), "newpoints.txt")
        self.path = read_path_log_orientation(points_path)

        self.face_path = []
        
        self.path_idx = 0
        self.face_path_idx = 0
        
        self.go_to_face = False

        self.number_of_faces_in_current_movement = 0

        self.all_goals_reached = False
        self.goal_reached = False

        if self.path:
            self.next_goal = True

        self.face_search = True
        # array containing face positions
        self.face_positions_and_images = []
        self.faces_dictionary = {}

        # This number is made up. The greatest measured distance is 4. The distance is probably in meters. 
        self.FACE_DISTANCE_TOLERANCE = 0.5

        # array of robot positions when faces are detected
        self.bot_positions = []
   
    def get_greeting_pose(self, coords : Tuple[int,int,int,int], dist : float, stamp, pose_of_detection: PoseWithCovarianceStamped) -> Pose:
        """
        Calculates the greeting position for the bot to travel to.
        """

        # Calculate the position of the detected face
        k_f = 554 # kinect focal length in pixels

        x1, x2, _, _ = coords

        face_x = self.dims[1] / 2 - (x1+x2)/2.

        angle_to_target = np.arctan2(face_x,k_f)

        # Get the angles in the base_link relative coordinate system
        # step away from image 0.4 units (probably meters)
        dist -= 0.4
        x, y = dist*np.cos(angle_to_target), dist*np.sin(angle_to_target)


        # Define a stamped message for transformation - in the "camera rgb frame"
        point_s = PointStamped()
        point_s.point.x = -y
        point_s.point.y = 0
        point_s.point.z = x
        point_s.header.frame_id = "camera_rgb_optical_frame"
        point_s.header.stamp = stamp

        # Define a quaternion for the rotation
        # Roatation is such that the image of the face is in the center of the robot view.
        q = Quaternion()
        q.x = 0
        q.y = 0
        q.z = math.sin(angle_to_target)
        q.w = math.cos(angle_to_target)

    
        q2 = pose_of_detection.pose.pose.orientation

        goal_quaternion = quaternion_multiply((q2.x, q2.y, q2.z, q2.w), (q.x, q.y, q.z, q.w))

        # Get the point in the "map" coordinate system
        try:
            point_world = self.tf_buf.transform(point_s, "map")

            # Create a Pose object with the same position
            pose = Pose()

            pose.position.x = point_world.point.x
            pose.position.y = point_world.point.y
            pose.position.z = point_world.point.z

            pose.orientation.x = goal_quaternion[0]
            pose.orientation.y = goal_quaternion[1]
            pose.orientation.z = goal_quaternion[2]
            pose.orientation.w = goal_quaternion[3]
            
        except Exception as e:
            print(e)
            pose = None

        return pose

    def status_reached(self) -> Tuple[bool, int]:
        """
        Function listenes for status updates on topic /move_base/status.

        If status is 3 (goal reached) or 4 (goal terminated), the goal is 'reached'.
        If status is 0 or 1 the goal is 'being processed', else there is an error.
        """
        status = rospy.wait_for_message("/move_base/status", GoalStatusArray)
        if status.status_list[-1].status in (0, 1):
            # goal is being processed
            return False,status.status_list[-1].status
        else:
            # goal is done (successfully or not)
            return True,status.status_list[-1].status

    def publish_new_position(self, log:bool=True) -> None:
        """
        Publishes a new position to the robot.

        If go_to_face, go to the 'position_idx' of the self.face_path, else go to 'position_idx' of self.path.
        Function updates the self.path_idx or self.face_path_idx.
        """
        msg = PoseStamped()
        msg.header.frame_id = "map"
        msg.header.stamp = rospy.Time().now()
        if self.go_to_face:
            position_idx = self.face_path_idx
            if position_idx >= len(self.face_path):
                return
            msg.pose.position.x = self.face_path[position_idx][0]
            msg.pose.position.y = self.face_path[position_idx][1]
            msg.pose.orientation.z = self.face_path[position_idx][3]
            msg.pose.orientation.w = self.face_path[position_idx][4]
            self.face_path_idx += 1
        else:
            position_idx = self.path_idx
            if position_idx >= len(self.path):
                return
            msg.pose.orientation.w = 1
            msg.pose.position.x = self.path[position_idx][0]
            msg.pose.position.y = self.path[position_idx][1]
            msg.pose.orientation.z = self.path[position_idx][3]
            msg.pose.orientation.w = self.path[position_idx][4]
            self.path_idx += 1
        if log:
            self.simple_goal_pub.publish(msg)
            obj, array = ("FACE", "face_path") if self.go_to_face else ("POINT", "path")
            rospy.loginfo(f"Visiting {obj} @ index {position_idx} in {array}.")
            rospy.loginfo(f"\n{msg.pose}")


    def should_add_new_face(self, pose, face_region_path: str, current_time) -> bool:
        """
        Calculates similarities between faces. 

        If the detected face is not near any other faces, it should get added.
        If the detected face is near other faces, nn should be run to determine if it's the same face or not.
        
        Function refreshes time of nearby faces.


        """
        # Calculate the distance to the marker
        min_dist = float("inf")
        min_face_region = None
        min_face = None
        min_filename = None
        min_time_before_refresh = None

        for filename, face in self.faces_dictionary.items():
            position, _, time_of_collection = face.values()
            dist = np.sqrt((pose.position.x - position[0])**2 + (pose.position.y - position[1])**2)
            if dist < min_dist:
                min_dist = dist
                min_face = face
                min_filename = filename
                min_time_before_refresh = time_of_collection
            # refresh timer for close enough faces
            if dist < self.FACE_DISTANCE_TOLERANCE:
                self.faces_dictionary[filename]["time"] = time.time()

        # if no faces are in the dictionary, add the new face
        if min_dist == float("inf") and self.face_positions_and_images:
            return False

        similarity = 0
        if min_dist < self.FACE_DISTANCE_TOLERANCE and min_face is not None and current_time-min_time_before_refresh > 20:
            face_region = _i.open(face_region_path)
            min_face_region = _i.open(os.path.join(os.path.dirname(__file__), f"../images/{min_filename}"))

            img1 = self.transform(face_region).unsqueeze(0)
            img2 = self.transform(min_face_region).unsqueeze(0)

            with torch.no_grad():
                try:
                    feature1 = self.model(img1)
                    feature2 = self.model(img2)
                except RuntimeError as e:
                    print(e)
                    return False

            similarity = torch.nn.functional.cosine_similarity(feature1, feature2)

            rospy.loginfo(f"Similarity score between new face and {min_filename} : {similarity}")

            # this similarity score was set arbitrarily, but it seems to work just fine
            # new face detected
            if similarity < NN_FACE_SIMILARITY_TOLERANCE:
                self.faces_dictionary[min_filename]["time"] = time.time()
                return True
            else:
                # update old face if new one is better
                face_region_width, face_region_height = face_region.size
                min_face_region_width, min_face_region_height = min_face_region.size

                if face_region_width * face_region_height > min_face_region_width * min_face_region_height:
                    self.faces_dictionary[min_filename]["time"] = time.time()
                    face_region.save(os.path.join(os.path.dirname(__file__), f"../images/{min_filename}"))
                    rospy.loginfo(f"UPDATED IMAGE {min_filename}! {[face_region_width, face_region_height]} -> {[min_face_region_width, min_face_region_height]}")
                    return False

        return min_dist > self.FACE_DISTANCE_TOLERANCE

    # not our function
    def get_pose(self,coords,dist,stamp):
        # Calculate the position of the detected face

        k_f = 554 # kinect focal length in pixels

        x1, x2, y1, y2 = coords

        face_x = self.dims[1] / 2 - (x1+x2)/2.
        face_y = self.dims[0] / 2 - (y1+y2)/2.

        angle_to_target = np.arctan2(face_x,k_f)

        # Get the angles in the base_link relative coordinate system
        x, y = dist*np.cos(angle_to_target), dist*np.sin(angle_to_target)

        # Define a stamped message for transformation - in the "camera rgb frame"
        point_s = PointStamped()
        point_s.point.x = -y
        point_s.point.y = 0
        point_s.point.z = x
        point_s.header.frame_id = "camera_rgb_optical_frame"
        point_s.header.stamp = stamp

        # Get the point in the "map" coordinate system
        try:
            point_world = self.tf_buf.transform(point_s, "map")

            # Create a Pose object with the same position
            pose = Pose()
            pose.position.x = point_world.point.x
            pose.position.y = point_world.point.y
            pose.position.z = point_world.point.z
        except Exception as e:
            print(e)
            pose = None

        return pose


    def find_faces(self):

        # Get the next rgb and depth images that are posted from the camera
        try:
            rgb_image_message = rospy.wait_for_message("/camera/rgb/image_raw", Image)
        except Exception as e:
            print(e)
            return 0

        # get robot position in moment of taking a picture
        p = rospy.wait_for_message("/amcl_pose", PoseWithCovarianceStamped)

        try:
            depth_image_message = rospy.wait_for_message("/camera/depth/image_raw", Image)
        except Exception as e:
            print(e)
            return 0

        # Convert the images into a OpenCV (numpy) format

        try:
            rgb_image = self.bridge.imgmsg_to_cv2(rgb_image_message, "bgr8")
        except CvBridgeError as e:
            print(e)

        try:
            depth_image = self.bridge.imgmsg_to_cv2(depth_image_message, "32FC1")
        except CvBridgeError as e:
            print(e)

        # Set the dimensions of the image
        self.dims = rgb_image.shape
        h = self.dims[0]
        w = self.dims[1]

        # Detect the faces in the image
        blob = cv2.dnn.blobFromImage(cv2.resize(rgb_image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))
        self.face_net.setInput(blob)

        # no false positives yet, will keep as it is
        face_detections = self.face_net.forward()

        p_position = p.pose.pose.position
        p_orientation = p.pose.pose.orientation

        for i in range(0, face_detections.shape[2]):
            confidence = face_detections[0, 0, i, 2]
            if confidence>0.50:
                rospy.loginfo("Saw new face.")
                box = face_detections[0,0,i,3:7] * np.array([w,h,w,h])
                box = box.astype('int')
                x1, y1, x2, y2 = box[0], box[1], box[2], box[3]
                ratio = abs(y2-y1)/abs(x2-x1)
                print(f"Ratio is {ratio}")
                if  ratio > 1.5:
                    print(f"Skipping face. Not a nice image.")
                    return


                # Extract region containing face
                face_region = rgb_image[y1:y2, x1:x2]
                relative_path_to_face_region = os.path.join(os.path.dirname(__file__), f"../images/face_region.jpg")
                try:
                    cv2.imwrite(relative_path_to_face_region, face_region) # Save the face image
                except cv2.error:
                    # TODO: Assertion error, emtpy image
                    print(f"face_region is None. Not saving image to {relative_path_to_face_region}.")
                    continue

                # Find the distance to the detected face
                face_distance = float(np.nanmean(depth_image[y1:y2,x1:x2]))

                # Get the time that the depth image was recieved
                depth_time = depth_image_message.header.stamp

                # Find the location of the detected face
                pose = self.get_pose((x1,x2,y1,y2), face_distance, depth_time)

                if pose is not None:

                    # Create a marker used for visualization
                    self.marker_num += 1
                    marker = Marker()
                    marker.header.stamp = rospy.Time(0)
                    marker.header.frame_id = 'map'
                    marker.pose = pose
                    marker.type = Marker.CUBE
                    marker.action = Marker.ADD
                    marker.frame_locked = False
                    marker.lifetime = rospy.Duration.from_sec(10)
                    marker.id = self.marker_num
                    marker.scale = Vector3(0.1, 0.1, 0.1)
                    marker.color = ColorRGBA(0, 1, 0, 1)
                    current_time = time.time()
                    if self.should_add_new_face(pose, relative_path_to_face_region, current_time):
                        self.bot_positions.append((p_position, p_orientation, face_distance))
                        position = (pose.position.x, pose.position.y, pose.position.z)
                        
                        current_face_properties = {
                                "position": position,
                                "face_region_array": face_region,
                                "time": time.time(),
                                }

                        # SHOULD BE BEFORE APPENDING GREETING_POSITION
                        filename = f"face_{len(self.face_path)}.jpg"
                        self.faces_dictionary.update({filename:current_face_properties})

                        self.face_positions_and_images.append((position, face_region))
                        
                        relative_path_to_image = os.path.join(os.path.dirname(__file__), f"../images/{filename}")
                        cv2.imwrite(relative_path_to_image, face_region) # Save the face image

                        greeting_pose = self.get_greeting_pose((x1,x2,y1,y2), face_distance, depth_time, p)
                        greeting_position = (
                                greeting_pose.position.x,
                                greeting_pose.position.y,
                                greeting_pose.position.z,
                                greeting_pose.orientation.z,
                                greeting_pose.orientation.w,
                                )
                        self.face_path.append(greeting_position)

                        # once face is detected, cancel goal and set go_to_face to true
                        cancel_msg = GoalID()

                         #UNCOMENT TO GO TO FACES
                        self.cancel_goal_pub.publish(cancel_msg)
                        self.path_idx -= 1
                        self.go_to_face = True

                        self.marker_array.markers.append(marker)
                        self.markers_pub.publish(self.marker_array)

def main():
    relative_path_to_image_dir = os.path.join(os.path.dirname(__file__), f"../images/")
    if os.path.exists(relative_path_to_image_dir):
        shutil.rmtree(relative_path_to_image_dir)
    os.mkdir(relative_path_to_image_dir)

    face_finder = face_localizer()

    rate = rospy.Rate(10)

    # BOT NEEDS TO SLEEP BEFORE TO FUNCTION!
    rospy.sleep(1)
    face_finder.publish_new_position()                

    while not rospy.is_shutdown():
        # We scan for faces every 1/10 of a second.
        face_finder.find_faces()

        # check status
        reached, status = face_finder.status_reached() 
        
        # either we reached the goal or we faced an error
        if reached:
            # reached goal
            if status == 3 and face_finder.go_to_face:
                # here we reached a goal (we parked before the face)
                speak_to_person()
                # we greeted, going onto the next position
                face_finder.go_to_face = False
                # Reached all faces
                if face_finder.face_path_idx == NUMBER_OF_FACES_ON_THE_MAP:
                    rospy.loginfo(f"Found all {NUMBER_OF_FACES_ON_THE_MAP} faces, will stop all other goals.")
                    break
            # stuck in place
            elif status == 4:
                cancel_msg = GoalID()
                face_finder.cancel_goal_pub.publish(cancel_msg)
                rospy.sleep(1)
            # if we reached the goal, but we are not going to a face, we need to go to the next position
            face_finder.publish_new_position()
        # check if we finished the path
        elif face_finder.path_idx == len(face_finder.path):
            rospy.loginfo(f"Found {len(face_finder.face_path)}/{NUMBER_OF_FACES_ON_THE_MAP} faces, but traversed the whole path, will stop.")
            break

        rate.sleep()


if __name__ == '__main__':
    main()
